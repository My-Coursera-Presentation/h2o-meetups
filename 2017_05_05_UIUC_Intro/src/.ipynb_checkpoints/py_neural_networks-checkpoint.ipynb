{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import h2o \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display matplotlib graphics in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_112\"; Java(TM) SE Runtime Environment (build 1.8.0_112-b16); Java HotSpot(TM) 64-Bit Server VM (build 25.112-b16, mixed mode)\n",
      "  Starting server from /Users/phall/anaconda/lib/python3.5/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/tc/0ss1l73113j3wdyjsxmy1j2r0000gn/T/tmp2hd873kl\n",
      "  JVM stdout: /var/folders/tc/0ss1l73113j3wdyjsxmy1j2r0000gn/T/tmp2hd873kl/h2o_phall_started_from_python.out\n",
      "  JVM stderr: /var/folders/tc/0ss1l73113j3wdyjsxmy1j2r0000gn/T/tmp2hd873kl/h2o_phall_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.3.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 2 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_phall_l09ys6</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster version:        3.10.3.4\n",
       "H2O cluster version age:    1 month and 2 days\n",
       "H2O cluster name:           H2O_from_python_phall_l09ys6\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "Python version:             3.5.2 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start and connect to h2o server\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load clean data\n",
    "path = '/Users/phall/workspace/GWU_data_mining/03_regression/data/loan_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define input variable measurement levels \n",
    "# strings automatically parsed as enums (nominal)\n",
    "# numbers automatically parsed as numeric\n",
    "col_types = {'bad_loan': 'enum'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "frame = h2o.import_file(path=path, col_types=col_types) # multi-threaded import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:163987\n",
      "Cols:18\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>id               </th><th>bad_loan  </th><th>GRP_REP_home_ownership  </th><th>GRP_addr_state    </th><th>GRP_home_ownership  </th><th>GRP_purpose       </th><th>GRP_verification_status  </th><th>_WARN_  </th><th>STD_IMP_REP_annual_inc  </th><th>STD_IMP_REP_delinq_2yrs  </th><th>STD_IMP_REP_dti      </th><th>STD_IMP_REP_emp_length  </th><th>STD_IMP_REP_int_rate  </th><th>STD_IMP_REP_loan_amnt  </th><th>STD_IMP_REP_longest_credit_lengt  </th><th>STD_IMP_REP_revol_util  </th><th>STD_IMP_REP_term_length  </th><th>STD_IMP_REP_total_acc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>enum      </td><td>int                     </td><td>int               </td><td>int                 </td><td>int               </td><td>int                      </td><td>int     </td><td>real                    </td><td>real                     </td><td>real                 </td><td>real                    </td><td>real                  </td><td>real                   </td><td>real                              </td><td>real                    </td><td>real                     </td><td>real                   </td></tr>\n",
       "<tr><td>mins   </td><td>10001.0          </td><td>          </td><td>1.0                     </td><td>1.0               </td><td>1.0                 </td><td>1.0               </td><td>1.0                      </td><td>NaN     </td><td>-1.767455639            </td><td>-0.39219617              </td><td>-2.119639396         </td><td>-1.6213902740000001     </td><td>-1.907046215          </td><td>-1.587129405           </td><td>-2.22445124                       </td><td>-2.164541326            </td><td>-0.516495577             </td><td>-2.058861889           </td></tr>\n",
       "<tr><td>mean   </td><td>91994.0          </td><td>          </td><td>2.5740028172964924      </td><td>11.409337325519703</td><td>2.5740028172964924  </td><td>3.2449401476946345</td><td>2.340356247751345        </td><td>0.0     </td><td>2.38744452882879e-11    </td><td>2.2959296297769782e-12   </td><td>6.807013811211564e-11</td><td>-3.566867876239133e-11  </td><td>-8.948753565861857e-12</td><td>8.311927579716105e-11  </td><td>5.0612534090153816e-11            </td><td>-1.4734128080190765e-11 </td><td>-1.5009542966560638e-10  </td><td>8.060924856225354e-13  </td></tr>\n",
       "<tr><td>maxs   </td><td>173987.0         </td><td>          </td><td>5.0                     </td><td>37.0              </td><td>5.0                 </td><td>14.0              </td><td>3.0                      </td><td>NaN     </td><td>4.6180619798            </td><td>4.1566950661             </td><td>3.0371487270000004   </td><td>1.2288169612            </td><td>2.8376799992          </td><td>2.7671323946           </td><td>3.1431598296                      </td><td>3.0363495275            </td><td>1.9718787627             </td><td>3.0684672884           </td></tr>\n",
       "<tr><td>sigma  </td><td>47339.11363414683</td><td>          </td><td>0.6675260435449262      </td><td>9.971926133461404 </td><td>0.6675260435449262  </td><td>2.2672892075259754</td><td>0.5040864341768772       </td><td>-0.0    </td><td>0.9999999999982868      </td><td>0.9999999999212518       </td><td>1.0000000000037712   </td><td>1.0000000000339833      </td><td>1.0000000000199503    </td><td>0.999999999985285      </td><td>0.9999999999850594                </td><td>1.000000000017688       </td><td>1.0000000000642086       </td><td>1.0000000000331841     </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>          </td><td>0                       </td><td>0                 </td><td>0                   </td><td>0                 </td><td>0                        </td><td>0       </td><td>0                       </td><td>0                        </td><td>0                    </td><td>0                       </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                       </td><td>0                        </td><td>0                      </td></tr>\n",
       "<tr><td>missing</td><td>0                </td><td>0         </td><td>0                       </td><td>0                 </td><td>0                   </td><td>0                 </td><td>0                        </td><td>163987  </td><td>0                       </td><td>0                        </td><td>0                    </td><td>0                       </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                       </td><td>0                        </td><td>0                      </td></tr>\n",
       "<tr><td>0      </td><td>10001.0          </td><td>0         </td><td>3.0                     </td><td>14.0              </td><td>3.0                 </td><td>3.0               </td><td>2.0                      </td><td>nan     </td><td>-1.1992995020000001     </td><td>-0.39219617              </td><td>1.5712460425         </td><td>1.2288169612            </td><td>-0.7047730510000001   </td><td>-1.019182214           </td><td>1.6839024850000002                </td><td>1.1858716502            </td><td>-0.516495577             </td><td>-1.359278248           </td></tr>\n",
       "<tr><td>1      </td><td>10002.0          </td><td>1         </td><td>3.0                     </td><td>10.0              </td><td>3.0                 </td><td>8.0               </td><td>2.0                      </td><td>nan     </td><td>-1.04507688             </td><td>-0.39219617              </td><td>-1.9861534850000002  </td><td>-1.6213902740000001     </td><td>0.3572732234          </td><td>-1.3347084310000001    </td><td>-0.42059567400000003              </td><td>-1.7882703350000002     </td><td>1.9718787627             </td><td>-1.7965180230000002    </td></tr>\n",
       "<tr><td>2      </td><td>10003.0          </td><td>0         </td><td>3.0                     </td><td>7.0               </td><td>3.0                 </td><td>7.0               </td><td>3.0                      </td><td>nan     </td><td>-1.501267394            </td><td>-0.39219617              </td><td>-0.9556422520000001  </td><td>1.2288169612            </td><td>0.5158905241          </td><td>-1.34732948            </td><td>-0.7212382690000001               </td><td>1.7782983174            </td><td>-0.516495577             </td><td>-1.271830292           </td></tr>\n",
       "<tr><td>3      </td><td>10004.0          </td><td>0         </td><td>3.0                     </td><td>2.0               </td><td>3.0                 </td><td>4.0               </td><td>2.0                      </td><td>nan     </td><td>-0.303921333            </td><td>-0.39219617              </td><td>0.5500788236         </td><td>1.2288169612            </td><td>-0.051913437          </td><td>-0.388129779           </td><td>0.0303682169                      </td><td>0.0325652593            </td><td>-0.516495577             </td><td>1.089264497            </td></tr>\n",
       "<tr><td>4      </td><td>10005.0          </td><td>0         </td><td>3.0                     </td><td>14.0              </td><td>3.0                 </td><td>10.0              </td><td>2.0                      </td><td>nan     </td><td>-0.890854259            </td><td>-0.39219617              </td><td>-0.624597193         </td><td>-0.7663281030000001     </td><td>-1.3369434530000002   </td><td>-1.019182214           </td><td>-0.8220262690000001               </td><td>-1.0317254690000002     </td><td>-0.516495577             </td><td>-1.0969343820000002    </td></tr>\n",
       "<tr><td>5      </td><td>10006.0          </td><td>0         </td><td>3.0                     </td><td>2.0               </td><td>3.0                 </td><td>8.0               </td><td>2.0                      </td><td>nan     </td><td>-0.5824090160000001     </td><td>-0.39219617              </td><td>-1.4054897720000001  </td><td>0.9437962377            </td><td>1.1319693155000001    </td><td>-1.271603188           </td><td>-1.623166051                      </td><td>1.3379811999            </td><td>-0.516495577             </td><td>-1.7965180230000002    </td></tr>\n",
       "<tr><td>6      </td><td>10007.0          </td><td>1         </td><td>4.0                     </td><td>2.0               </td><td>4.0                 </td><td>7.0               </td><td>2.0                      </td><td>nan     </td><td>-0.788039178            </td><td>-0.39219617              </td><td>-1.37879259          </td><td>-0.48130738             </td><td>1.7388529011          </td><td>-0.9434559220000001    </td><td>-1.17220216                       </td><td>-0.8596015050000001     </td><td>1.9718787627             </td><td>-1.0094864270000001    </td></tr>\n",
       "<tr><td>7      </td><td>10008.0          </td><td>1         </td><td>3.0                     </td><td>4.0               </td><td>3.0                 </td><td>4.0               </td><td>2.0                      </td><td>nan     </td><td>-1.430633434            </td><td>-0.39219617              </td><td>0.2937858745         </td><td>-1.6213902740000001     </td><td>-0.235817553          </td><td>-0.971853281           </td><td>-1.17220216                       </td><td>-0.703489072            </td><td>1.9718787627             </td><td>-1.883965979           </td></tr>\n",
       "<tr><td>8      </td><td>10009.0          </td><td>0         </td><td>4.0                     </td><td>14.0              </td><td>4.0                 </td><td>2.0               </td><td>3.0                      </td><td>nan     </td><td>0.0344814697            </td><td>-0.39219617              </td><td>0.032153489          </td><td>-0.196286656            </td><td>0.2147475328          </td><td>-0.8298664840000001    </td><td>-0.270274377                      </td><td>-1.339947451            </td><td>1.9718787627             </td><td>-0.135006875           </td></tr>\n",
       "<tr><td>9      </td><td>10010.0          </td><td>0         </td><td>4.0                     </td><td>2.0               </td><td>4.0                 </td><td>2.0               </td><td>2.0                      </td><td>nan     </td><td>0.1115927805            </td><td>-0.39219617              </td><td>-0.680661276         </td><td>1.2288169612            </td><td>-0.235817553          </td><td>-0.13570880500000002   </td><td>1.0826172966                      </td><td>0.5213930910000001      </td><td>-0.516495577             </td><td>0.8269206315000001     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into 40% training, 30% validation, and 30% test\n",
    "train, valid, test = frame.split_frame([0.4, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_loan\n",
      "['GRP_REP_home_ownership', 'GRP_addr_state', 'GRP_home_ownership', 'GRP_purpose', 'GRP_verification_status', 'STD_IMP_REP_annual_inc', 'STD_IMP_REP_delinq_2yrs', 'STD_IMP_REP_dti', 'STD_IMP_REP_emp_length', 'STD_IMP_REP_int_rate', 'STD_IMP_REP_loan_amnt', 'STD_IMP_REP_longest_credit_lengt', 'STD_IMP_REP_revol_util', 'STD_IMP_REP_term_length', 'STD_IMP_REP_total_acc']\n"
     ]
    }
   ],
   "source": [
    "# assign target and inputs\n",
    "y = 'bad_loan'\n",
    "X = [name for name in frame.columns if name not in ['id', '_WARN_', y]]\n",
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set target to factor - for binary classification\n",
    "train[y] = train[y].asfactor()\n",
    "valid[y] = valid[y].asfactor()\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  nn_model\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1442579047751939\n",
      "RMSE: 0.3798129865804932\n",
      "LogLoss: 0.45529359040930995\n",
      "Mean Per-Class Error: 0.35266410512210133\n",
      "AUC: 0.6833671470385846\n",
      "Gini: 0.3667342940771692\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.18255730873624404: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>4978.0</td>\n",
       "<td>3057.0</td>\n",
       "<td>0.3805</td>\n",
       "<td> (3057.0/8035.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>614.0</td>\n",
       "<td>1276.0</td>\n",
       "<td>0.3249</td>\n",
       "<td> (614.0/1890.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>5592.0</td>\n",
       "<td>4333.0</td>\n",
       "<td>0.3699</td>\n",
       "<td> (3671.0/9925.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ---------------\n",
       "0      4978  3057  0.3805   (3057.0/8035.0)\n",
       "1      614   1276  0.3249   (614.0/1890.0)\n",
       "Total  5592  4333  0.3699   (3671.0/9925.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1825573</td>\n",
       "<td>0.4100916</td>\n",
       "<td>242.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1167755</td>\n",
       "<td>0.5621811</td>\n",
       "<td>326.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2322443</td>\n",
       "<td>0.3536721</td>\n",
       "<td>185.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5026745</td>\n",
       "<td>0.8095718</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.5026745</td>\n",
       "<td>0.5</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0557657</td>\n",
       "<td>1.0</td>\n",
       "<td>395.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.5137469</td>\n",
       "<td>0.9996266</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1825573</td>\n",
       "<td>0.2332837</td>\n",
       "<td>242.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1883810</td>\n",
       "<td>0.6434350</td>\n",
       "<td>235.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1825573</td>\n",
       "<td>0.6473359</td>\n",
       "<td>242.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.182557     0.410092  242\n",
       "max f2                       0.116776     0.562181  326\n",
       "max f0point5                 0.232244     0.353672  185\n",
       "max accuracy                 0.502674     0.809572  2\n",
       "max precision                0.502674     0.5       2\n",
       "max recall                   0.0557657    1         395\n",
       "max specificity              0.513747     0.999627  0\n",
       "max absolute_mcc             0.182557     0.233284  242\n",
       "max min_per_class_accuracy   0.188381     0.643435  235\n",
       "max mean_per_class_accuracy  0.182557     0.647336  242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.04 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100756</td>\n",
       "<td>0.4457002</td>\n",
       "<td>2.5731481</td>\n",
       "<td>2.5731481</td>\n",
       "<td>0.49</td>\n",
       "<td>0.49</td>\n",
       "<td>0.0259259</td>\n",
       "<td>0.0259259</td>\n",
       "<td>157.3148148</td>\n",
       "<td>157.3148148</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200504</td>\n",
       "<td>0.4196381</td>\n",
       "<td>2.3339212</td>\n",
       "<td>2.4541358</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.4673367</td>\n",
       "<td>0.0232804</td>\n",
       "<td>0.0492063</td>\n",
       "<td>133.3921223</td>\n",
       "<td>145.4135758</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300252</td>\n",
       "<td>0.3998050</td>\n",
       "<td>2.3339212</td>\n",
       "<td>2.4141987</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.4597315</td>\n",
       "<td>0.0232804</td>\n",
       "<td>0.0724868</td>\n",
       "<td>133.3921223</td>\n",
       "<td>141.4198715</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.3850111</td>\n",
       "<td>1.7504409</td>\n",
       "<td>2.2486772</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.4282116</td>\n",
       "<td>0.0174603</td>\n",
       "<td>0.0899471</td>\n",
       "<td>75.0440917</td>\n",
       "<td>124.8677249</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500756</td>\n",
       "<td>0.3704506</td>\n",
       "<td>1.8379630</td>\n",
       "<td>2.1660386</td>\n",
       "<td>0.35</td>\n",
       "<td>0.4124748</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.1084656</td>\n",
       "<td>83.7962963</td>\n",
       "<td>116.6038559</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000504</td>\n",
       "<td>0.3225510</td>\n",
       "<td>1.8527852</td>\n",
       "<td>2.0095696</td>\n",
       "<td>0.3528226</td>\n",
       "<td>0.3826788</td>\n",
       "<td>0.0925926</td>\n",
       "<td>0.2010582</td>\n",
       "<td>85.2785245</td>\n",
       "<td>100.9569633</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500252</td>\n",
       "<td>0.2869127</td>\n",
       "<td>1.7257371</td>\n",
       "<td>1.9150223</td>\n",
       "<td>0.3286290</td>\n",
       "<td>0.3646743</td>\n",
       "<td>0.0862434</td>\n",
       "<td>0.2873016</td>\n",
       "<td>72.5737114</td>\n",
       "<td>91.5022333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2606384</td>\n",
       "<td>1.4928155</td>\n",
       "<td>1.8095238</td>\n",
       "<td>0.2842742</td>\n",
       "<td>0.3445844</td>\n",
       "<td>0.0746032</td>\n",
       "<td>0.3619048</td>\n",
       "<td>49.2815540</td>\n",
       "<td>80.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000504</td>\n",
       "<td>0.2223227</td>\n",
       "<td>1.4542938</td>\n",
       "<td>1.6910740</td>\n",
       "<td>0.2769386</td>\n",
       "<td>0.3220282</td>\n",
       "<td>0.1455026</td>\n",
       "<td>0.5074074</td>\n",
       "<td>45.4293813</td>\n",
       "<td>69.1074049</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.1908392</td>\n",
       "<td>1.2387193</td>\n",
       "<td>1.5780423</td>\n",
       "<td>0.2358871</td>\n",
       "<td>0.3005038</td>\n",
       "<td>0.1238095</td>\n",
       "<td>0.6312169</td>\n",
       "<td>23.8719278</td>\n",
       "<td>57.8042328</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000504</td>\n",
       "<td>0.1670006</td>\n",
       "<td>0.9201714</td>\n",
       "<td>1.4464151</td>\n",
       "<td>0.1752266</td>\n",
       "<td>0.2754382</td>\n",
       "<td>0.0920635</td>\n",
       "<td>0.7232804</td>\n",
       "<td>-7.9828642</td>\n",
       "<td>44.6415112</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1465621</td>\n",
       "<td>0.7146457</td>\n",
       "<td>1.3245150</td>\n",
       "<td>0.1360887</td>\n",
       "<td>0.2522250</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.7947090</td>\n",
       "<td>-28.5354263</td>\n",
       "<td>32.4514991</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999496</td>\n",
       "<td>0.1273411</td>\n",
       "<td>0.6617090</td>\n",
       "<td>1.2298693</td>\n",
       "<td>0.1260081</td>\n",
       "<td>0.2342018</td>\n",
       "<td>0.0661376</td>\n",
       "<td>0.8608466</td>\n",
       "<td>-33.8290984</td>\n",
       "<td>22.9869313</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1089525</td>\n",
       "<td>0.5552758</td>\n",
       "<td>1.1455026</td>\n",
       "<td>0.1057402</td>\n",
       "<td>0.2181360</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.9164021</td>\n",
       "<td>-44.4724180</td>\n",
       "<td>14.5502646</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999496</td>\n",
       "<td>0.0897306</td>\n",
       "<td>0.4923115</td>\n",
       "<td>1.0729584</td>\n",
       "<td>0.09375</td>\n",
       "<td>0.2043215</td>\n",
       "<td>0.0492063</td>\n",
       "<td>0.9656085</td>\n",
       "<td>-50.7688492</td>\n",
       "<td>7.2958354</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0475398</td>\n",
       "<td>0.3437422</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0654582</td>\n",
       "<td>0.1904282</td>\n",
       "<td>0.0343915</td>\n",
       "<td>1.0</td>\n",
       "<td>-65.6257826</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100756                   0.4457             2.57315   2.57315            0.49             0.49                        0.0259259       0.0259259                  157.315   157.315\n",
       "    2        0.0200504                   0.419638           2.33392   2.45414            0.444444         0.467337                    0.0232804       0.0492063                  133.392   145.414\n",
       "    3        0.0300252                   0.399805           2.33392   2.4142             0.444444         0.459732                    0.0232804       0.0724868                  133.392   141.42\n",
       "    4        0.04                        0.385011           1.75044   2.24868            0.333333         0.428212                    0.0174603       0.0899471                  75.0441   124.868\n",
       "    5        0.0500756                   0.370451           1.83796   2.16604            0.35             0.412475                    0.0185185       0.108466                   83.7963   116.604\n",
       "    6        0.10005                     0.322551           1.85279   2.00957            0.352823         0.382679                    0.0925926       0.201058                   85.2785   100.957\n",
       "    7        0.150025                    0.286913           1.72574   1.91502            0.328629         0.364674                    0.0862434       0.287302                   72.5737   91.5022\n",
       "    8        0.2                         0.260638           1.49282   1.80952            0.284274         0.344584                    0.0746032       0.361905                   49.2816   80.9524\n",
       "    9        0.30005                     0.222323           1.45429   1.69107            0.276939         0.322028                    0.145503        0.507407                   45.4294   69.1074\n",
       "    10       0.4                         0.190839           1.23872   1.57804            0.235887         0.300504                    0.12381         0.631217                   23.8719   57.8042\n",
       "    11       0.50005                     0.167001           0.920171  1.44642            0.175227         0.275438                    0.0920635       0.72328                    -7.98286  44.6415\n",
       "    12       0.6                         0.146562           0.714646  1.32451            0.136089         0.252225                    0.0714286       0.794709                   -28.5354  32.4515\n",
       "    13       0.69995                     0.127341           0.661709  1.22987            0.126008         0.234202                    0.0661376       0.860847                   -33.8291  22.9869\n",
       "    14       0.8                         0.108953           0.555276  1.1455             0.10574          0.218136                    0.0555556       0.916402                   -44.4724  14.5503\n",
       "    15       0.89995                     0.0897306          0.492312  1.07296            0.09375          0.204322                    0.0492063       0.965608                   -50.7688  7.29584\n",
       "    16       1                           0.0475398          0.343742  1                  0.0654582        0.190428                    0.0343915       1                          -65.6258  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.14642873687247504\n",
      "RMSE: 0.3826600800612406\n",
      "LogLoss: 0.4615471411890631\n",
      "Mean Per-Class Error: 0.37065434983055967\n",
      "AUC: 0.6710739742243093\n",
      "Gini: 0.3421479484486185\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.18706053860867397: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>25402.0</td>\n",
       "<td>14439.0</td>\n",
       "<td>0.3624</td>\n",
       "<td> (14439.0/39841.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>3601.0</td>\n",
       "<td>5903.0</td>\n",
       "<td>0.3789</td>\n",
       "<td> (3601.0/9504.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>29003.0</td>\n",
       "<td>20342.0</td>\n",
       "<td>0.3656</td>\n",
       "<td> (18040.0/49345.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      25402  14439  0.3624   (14439.0/39841.0)\n",
       "1      3601   5903   0.3789   (3601.0/9504.0)\n",
       "Total  29003  20342  0.3656   (18040.0/49345.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1870605</td>\n",
       "<td>0.3955639</td>\n",
       "<td>235.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1144959</td>\n",
       "<td>0.5600621</td>\n",
       "<td>325.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2648909</td>\n",
       "<td>0.3509810</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4767275</td>\n",
       "<td>0.8074577</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.4767275</td>\n",
       "<td>0.5079365</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0516134</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.5362201</td>\n",
       "<td>0.9999749</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1887886</td>\n",
       "<td>0.2072674</td>\n",
       "<td>233.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1853050</td>\n",
       "<td>0.6277357</td>\n",
       "<td>237.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1870605</td>\n",
       "<td>0.6293457</td>\n",
       "<td>235.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.187061     0.395564  235\n",
       "max f2                       0.114496     0.560062  325\n",
       "max f0point5                 0.264891     0.350981  153\n",
       "max accuracy                 0.476728     0.807458  14\n",
       "max precision                0.476728     0.507937  14\n",
       "max recall                   0.0516134    1         397\n",
       "max specificity              0.53622      0.999975  0\n",
       "max absolute_mcc             0.188789     0.207267  233\n",
       "max min_per_class_accuracy   0.185305     0.627736  237\n",
       "max mean_per_class_accuracy  0.187061     0.629346  235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100111</td>\n",
       "<td>0.4504053</td>\n",
       "<td>2.5119308</td>\n",
       "<td>2.5119308</td>\n",
       "<td>0.4838057</td>\n",
       "<td>0.4838057</td>\n",
       "<td>0.0251473</td>\n",
       "<td>0.0251473</td>\n",
       "<td>151.1930838</td>\n",
       "<td>151.1930838</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200020</td>\n",
       "<td>0.4237488</td>\n",
       "<td>2.2537388</td>\n",
       "<td>2.3829656</td>\n",
       "<td>0.4340771</td>\n",
       "<td>0.4589666</td>\n",
       "<td>0.0225168</td>\n",
       "<td>0.0476641</td>\n",
       "<td>125.3738791</td>\n",
       "<td>138.2965611</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300132</td>\n",
       "<td>0.4040086</td>\n",
       "<td>2.2281562</td>\n",
       "<td>2.3313276</td>\n",
       "<td>0.4291498</td>\n",
       "<td>0.4490209</td>\n",
       "<td>0.0223064</td>\n",
       "<td>0.0699705</td>\n",
       "<td>122.8156225</td>\n",
       "<td>133.1327639</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400041</td>\n",
       "<td>0.3870950</td>\n",
       "<td>1.9799201</td>\n",
       "<td>2.2435648</td>\n",
       "<td>0.3813387</td>\n",
       "<td>0.4321175</td>\n",
       "<td>0.0197811</td>\n",
       "<td>0.0897517</td>\n",
       "<td>97.9920059</td>\n",
       "<td>124.3564753</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500152</td>\n",
       "<td>0.3732803</td>\n",
       "<td>1.9443816</td>\n",
       "<td>2.1836796</td>\n",
       "<td>0.3744939</td>\n",
       "<td>0.4205835</td>\n",
       "<td>0.0194655</td>\n",
       "<td>0.1092172</td>\n",
       "<td>94.4381611</td>\n",
       "<td>118.3679635</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000101</td>\n",
       "<td>0.3211045</td>\n",
       "<td>1.8625625</td>\n",
       "<td>2.0231536</td>\n",
       "<td>0.3587353</td>\n",
       "<td>0.3896657</td>\n",
       "<td>0.0931187</td>\n",
       "<td>0.2023359</td>\n",
       "<td>86.2562466</td>\n",
       "<td>102.3153585</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500051</td>\n",
       "<td>0.2854143</td>\n",
       "<td>1.6584172</td>\n",
       "<td>1.9015912</td>\n",
       "<td>0.3194163</td>\n",
       "<td>0.3662524</td>\n",
       "<td>0.0829125</td>\n",
       "<td>0.2852483</td>\n",
       "<td>65.8417201</td>\n",
       "<td>90.1591216</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2583692</td>\n",
       "<td>1.5047821</td>\n",
       "<td>1.8023990</td>\n",
       "<td>0.2898257</td>\n",
       "<td>0.3471476</td>\n",
       "<td>0.0752315</td>\n",
       "<td>0.3604798</td>\n",
       "<td>50.4782105</td>\n",
       "<td>80.2398990</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000101</td>\n",
       "<td>0.2191072</td>\n",
       "<td>1.2866962</td>\n",
       "<td>1.6304865</td>\n",
       "<td>0.2478217</td>\n",
       "<td>0.3140367</td>\n",
       "<td>0.1286827</td>\n",
       "<td>0.4891625</td>\n",
       "<td>28.6696222</td>\n",
       "<td>63.0486455</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.1898059</td>\n",
       "<td>1.1806752</td>\n",
       "<td>1.5180450</td>\n",
       "<td>0.2274017</td>\n",
       "<td>0.2923802</td>\n",
       "<td>0.1180556</td>\n",
       "<td>0.6072180</td>\n",
       "<td>18.0675190</td>\n",
       "<td>51.8045034</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000101</td>\n",
       "<td>0.1661769</td>\n",
       "<td>0.9132071</td>\n",
       "<td>1.3970676</td>\n",
       "<td>0.1758865</td>\n",
       "<td>0.2690796</td>\n",
       "<td>0.0913300</td>\n",
       "<td>0.6985480</td>\n",
       "<td>-8.6792870</td>\n",
       "<td>39.7067647</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1458621</td>\n",
       "<td>0.8386793</td>\n",
       "<td>1.3040123</td>\n",
       "<td>0.1615322</td>\n",
       "<td>0.2511568</td>\n",
       "<td>0.0838594</td>\n",
       "<td>0.7824074</td>\n",
       "<td>-16.1320743</td>\n",
       "<td>30.4012346</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999899</td>\n",
       "<td>0.1270779</td>\n",
       "<td>0.6639983</td>\n",
       "<td>1.2125897</td>\n",
       "<td>0.1278881</td>\n",
       "<td>0.2335485</td>\n",
       "<td>0.0663931</td>\n",
       "<td>0.8488005</td>\n",
       "<td>-33.6001742</td>\n",
       "<td>21.2589703</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1086840</td>\n",
       "<td>0.6354575</td>\n",
       "<td>1.1404409</td>\n",
       "<td>0.1223911</td>\n",
       "<td>0.2196524</td>\n",
       "<td>0.0635522</td>\n",
       "<td>0.9123527</td>\n",
       "<td>-36.4542504</td>\n",
       "<td>14.0440867</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999899</td>\n",
       "<td>0.0893100</td>\n",
       "<td>0.5040494</td>\n",
       "<td>1.0697371</td>\n",
       "<td>0.0970815</td>\n",
       "<td>0.2060347</td>\n",
       "<td>0.0503998</td>\n",
       "<td>0.9627525</td>\n",
       "<td>-49.5950609</td>\n",
       "<td>6.9737072</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0462727</td>\n",
       "<td>0.3724370</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0717325</td>\n",
       "<td>0.1926031</td>\n",
       "<td>0.0372475</td>\n",
       "<td>1.0</td>\n",
       "<td>-62.7562991</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100111                   0.450405           2.51193   2.51193            0.483806         0.483806                    0.0251473       0.0251473                  151.193   151.193\n",
       "    2        0.020002                    0.423749           2.25374   2.38297            0.434077         0.458967                    0.0225168       0.0476641                  125.374   138.297\n",
       "    3        0.0300132                   0.404009           2.22816   2.33133            0.42915          0.449021                    0.0223064       0.0699705                  122.816   133.133\n",
       "    4        0.0400041                   0.387095           1.97992   2.24356            0.381339         0.432118                    0.0197811       0.0897517                  97.992    124.356\n",
       "    5        0.0500152                   0.37328            1.94438   2.18368            0.374494         0.420583                    0.0194655       0.109217                   94.4382   118.368\n",
       "    6        0.10001                     0.321105           1.86256   2.02315            0.358735         0.389666                    0.0931187       0.202336                   86.2562   102.315\n",
       "    7        0.150005                    0.285414           1.65842   1.90159            0.319416         0.366252                    0.0829125       0.285248                   65.8417   90.1591\n",
       "    8        0.2                         0.258369           1.50478   1.8024             0.289826         0.347148                    0.0752315       0.36048                    50.4782   80.2399\n",
       "    9        0.30001                     0.219107           1.2867    1.63049            0.247822         0.314037                    0.128683        0.489162                   28.6696   63.0486\n",
       "    10       0.4                         0.189806           1.18068   1.51805            0.227402         0.29238                     0.118056        0.607218                   18.0675   51.8045\n",
       "    11       0.50001                     0.166177           0.913207  1.39707            0.175887         0.26908                     0.09133         0.698548                   -8.67929  39.7068\n",
       "    12       0.6                         0.145862           0.838679  1.30401            0.161532         0.251157                    0.0838594       0.782407                   -16.1321  30.4012\n",
       "    13       0.69999                     0.127078           0.663998  1.21259            0.127888         0.233549                    0.0663931       0.848801                   -33.6002  21.259\n",
       "    14       0.8                         0.108684           0.635457  1.14044            0.122391         0.219652                    0.0635522       0.912353                   -36.4543  14.0441\n",
       "    15       0.89999                     0.08931            0.504049  1.06974            0.0970815        0.206035                    0.0503998       0.962753                   -49.5951  6.97371\n",
       "    16       1                           0.0462727          0.372437  1                  0.0717325        0.192603                    0.0372475       1                          -62.7563  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:33</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:36</td>\n",
       "<td> 3.621 sec</td>\n",
       "<td>59917 obs/sec</td>\n",
       "<td>1.5264675</td>\n",
       "<td>1</td>\n",
       "<td>100063.0</td>\n",
       "<td>0.3803374</td>\n",
       "<td>0.4568246</td>\n",
       "<td>0.6825450</td>\n",
       "<td>2.4681217</td>\n",
       "<td>0.3635264</td>\n",
       "<td>0.3830875</td>\n",
       "<td>0.4625501</td>\n",
       "<td>0.6709136</td>\n",
       "<td>2.5434614</td>\n",
       "<td>0.3672510</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:37</td>\n",
       "<td> 4.951 sec</td>\n",
       "<td>73495 obs/sec</td>\n",
       "<td>3.0496095</td>\n",
       "<td>2</td>\n",
       "<td>199908.0</td>\n",
       "<td>0.3803906</td>\n",
       "<td>0.4567671</td>\n",
       "<td>0.6785649</td>\n",
       "<td>2.4681217</td>\n",
       "<td>0.3197985</td>\n",
       "<td>0.3829555</td>\n",
       "<td>0.4623713</td>\n",
       "<td>0.6677233</td>\n",
       "<td>2.5224410</td>\n",
       "<td>0.3647381</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:38</td>\n",
       "<td> 6.156 sec</td>\n",
       "<td>80631 obs/sec</td>\n",
       "<td>4.5782127</td>\n",
       "<td>3</td>\n",
       "<td>300111.0</td>\n",
       "<td>0.3835654</td>\n",
       "<td>0.4631281</td>\n",
       "<td>0.6806111</td>\n",
       "<td>2.5206349</td>\n",
       "<td>0.3515365</td>\n",
       "<td>0.3861158</td>\n",
       "<td>0.4690743</td>\n",
       "<td>0.6695800</td>\n",
       "<td>2.4804003</td>\n",
       "<td>0.4072753</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:40</td>\n",
       "<td> 9.134 sec</td>\n",
       "<td>74476 obs/sec</td>\n",
       "<td>6.1044819</td>\n",
       "<td>4</td>\n",
       "<td>400161.0</td>\n",
       "<td>0.3798130</td>\n",
       "<td>0.4552936</td>\n",
       "<td>0.6833671</td>\n",
       "<td>2.5731481</td>\n",
       "<td>0.3698741</td>\n",
       "<td>0.3826601</td>\n",
       "<td>0.4615471</td>\n",
       "<td>0.6710740</td>\n",
       "<td>2.5119308</td>\n",
       "<td>0.3655892</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:43</td>\n",
       "<td>10.423 sec</td>\n",
       "<td>77473 obs/sec</td>\n",
       "<td>7.6301104</td>\n",
       "<td>5</td>\n",
       "<td>500169.0</td>\n",
       "<td>0.3822015</td>\n",
       "<td>0.4587695</td>\n",
       "<td>0.6818303</td>\n",
       "<td>2.4156085</td>\n",
       "<td>0.3847859</td>\n",
       "<td>0.3852804</td>\n",
       "<td>0.4658709</td>\n",
       "<td>0.6700875</td>\n",
       "<td>2.4593800</td>\n",
       "<td>0.3869490</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:44</td>\n",
       "<td>11.770 sec</td>\n",
       "<td>78978 obs/sec</td>\n",
       "<td>9.1554491</td>\n",
       "<td>6</td>\n",
       "<td>600158.0</td>\n",
       "<td>0.3796571</td>\n",
       "<td>0.4549017</td>\n",
       "<td>0.6845051</td>\n",
       "<td>2.6781746</td>\n",
       "<td>0.3676574</td>\n",
       "<td>0.3828903</td>\n",
       "<td>0.4620906</td>\n",
       "<td>0.6704928</td>\n",
       "<td>2.4804003</td>\n",
       "<td>0.3584355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:45</td>\n",
       "<td>13.006 sec</td>\n",
       "<td>81154 obs/sec</td>\n",
       "<td>10.6766079</td>\n",
       "<td>7</td>\n",
       "<td>699873.0</td>\n",
       "<td>0.3933949</td>\n",
       "<td>0.4845039</td>\n",
       "<td>0.6836735</td>\n",
       "<td>2.4681217</td>\n",
       "<td>0.3337028</td>\n",
       "<td>0.3961664</td>\n",
       "<td>0.4897310</td>\n",
       "<td>0.6694423</td>\n",
       "<td>2.5434614</td>\n",
       "<td>0.3675347</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:47</td>\n",
       "<td>14.189 sec</td>\n",
       "<td>83149 obs/sec</td>\n",
       "<td>12.1987277</td>\n",
       "<td>8</td>\n",
       "<td>799651.0</td>\n",
       "<td>0.3809532</td>\n",
       "<td>0.4578511</td>\n",
       "<td>0.6811333</td>\n",
       "<td>2.3105820</td>\n",
       "<td>0.3858942</td>\n",
       "<td>0.3838875</td>\n",
       "<td>0.4639604</td>\n",
       "<td>0.6692365</td>\n",
       "<td>2.4698902</td>\n",
       "<td>0.3593677</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:48</td>\n",
       "<td>15.377 sec</td>\n",
       "<td>84961 obs/sec</td>\n",
       "<td>13.7231053</td>\n",
       "<td>9</td>\n",
       "<td>899577.0</td>\n",
       "<td>0.3798589</td>\n",
       "<td>0.4559205</td>\n",
       "<td>0.6826783</td>\n",
       "<td>2.5206349</td>\n",
       "<td>0.3236272</td>\n",
       "<td>0.3831226</td>\n",
       "<td>0.4628092</td>\n",
       "<td>0.6683107</td>\n",
       "<td>2.4909105</td>\n",
       "<td>0.3675550</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:49</td>\n",
       "<td>16.534 sec</td>\n",
       "<td>86551 obs/sec</td>\n",
       "<td>15.2473151</td>\n",
       "<td>10</td>\n",
       "<td>999492.0</td>\n",
       "<td>0.3800183</td>\n",
       "<td>0.4561591</td>\n",
       "<td>0.6821077</td>\n",
       "<td>2.5731481</td>\n",
       "<td>0.3763224</td>\n",
       "<td>0.3834119</td>\n",
       "<td>0.4632990</td>\n",
       "<td>0.6675110</td>\n",
       "<td>2.5224410</td>\n",
       "<td>0.3700882</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:50</td>\n",
       "<td>17.735 sec</td>\n",
       "<td>87618 obs/sec</td>\n",
       "<td>16.7745912</td>\n",
       "<td>11</td>\n",
       "<td>1099608.0</td>\n",
       "<td>0.3825697</td>\n",
       "<td>0.4608990</td>\n",
       "<td>0.6813853</td>\n",
       "<td>2.4156085</td>\n",
       "<td>0.3781360</td>\n",
       "<td>0.3856555</td>\n",
       "<td>0.4672541</td>\n",
       "<td>0.6686799</td>\n",
       "<td>2.5960122</td>\n",
       "<td>0.3598338</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:38:50</td>\n",
       "<td>17.950 sec</td>\n",
       "<td>87569 obs/sec</td>\n",
       "<td>16.7745912</td>\n",
       "<td>11</td>\n",
       "<td>1099608.0</td>\n",
       "<td>0.3798130</td>\n",
       "<td>0.4552936</td>\n",
       "<td>0.6833671</td>\n",
       "<td>2.5731481</td>\n",
       "<td>0.3698741</td>\n",
       "<td>0.3826601</td>\n",
       "<td>0.4615471</td>\n",
       "<td>0.6710740</td>\n",
       "<td>2.5119308</td>\n",
       "<td>0.3655892</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  -----------  ---------------  ------------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "    2017-03-05 14:38:33  0.000 sec                     0         0             0            nan              nan                 nan             nan              nan                              nan                nan                   nan               nan                nan\n",
       "    2017-03-05 14:38:36  3.621 sec   59917 obs/sec     1.52647   1             100063       0.380337         0.456825            0.682545        2.46812          0.363526                         0.383087           0.46255               0.670914          2.54346            0.367251\n",
       "    2017-03-05 14:38:37  4.951 sec   73495 obs/sec     3.04961   2             199908       0.380391         0.456767            0.678565        2.46812          0.319798                         0.382955           0.462371              0.667723          2.52244            0.364738\n",
       "    2017-03-05 14:38:38  6.156 sec   80631 obs/sec     4.57821   3             300111       0.383565         0.463128            0.680611        2.52063          0.351537                         0.386116           0.469074              0.66958           2.4804             0.407275\n",
       "    2017-03-05 14:38:40  9.134 sec   74476 obs/sec     6.10448   4             400161       0.379813         0.455294            0.683367        2.57315          0.369874                         0.38266            0.461547              0.671074          2.51193            0.365589\n",
       "    2017-03-05 14:38:43  10.423 sec  77473 obs/sec     7.63011   5             500169       0.382201         0.45877             0.68183         2.41561          0.384786                         0.38528            0.465871              0.670087          2.45938            0.386949\n",
       "    2017-03-05 14:38:44  11.770 sec  78978 obs/sec     9.15545   6             600158       0.379657         0.454902            0.684505        2.67817          0.367657                         0.38289            0.462091              0.670493          2.4804             0.358436\n",
       "    2017-03-05 14:38:45  13.006 sec  81154 obs/sec     10.6766   7             699873       0.393395         0.484504            0.683674        2.46812          0.333703                         0.396166           0.489731              0.669442          2.54346            0.367535\n",
       "    2017-03-05 14:38:47  14.189 sec  83149 obs/sec     12.1987   8             799651       0.380953         0.457851            0.681133        2.31058          0.385894                         0.383888           0.46396               0.669237          2.46989            0.359368\n",
       "    2017-03-05 14:38:48  15.377 sec  84961 obs/sec     13.7231   9             899577       0.379859         0.45592             0.682678        2.52063          0.323627                         0.383123           0.462809              0.668311          2.49091            0.367555\n",
       "    2017-03-05 14:38:49  16.534 sec  86551 obs/sec     15.2473   10            999492       0.380018         0.456159            0.682108        2.57315          0.376322                         0.383412           0.463299              0.667511          2.52244            0.370088\n",
       "    2017-03-05 14:38:50  17.735 sec  87618 obs/sec     16.7746   11            1.09961e+06  0.38257          0.460899            0.681385        2.41561          0.378136                         0.385656           0.467254              0.66868           2.59601            0.359834\n",
       "    2017-03-05 14:38:50  17.950 sec  87569 obs/sec     16.7746   11            1.09961e+06  0.379813         0.455294            0.683367        2.57315          0.369874                         0.38266            0.461547              0.671074          2.51193            0.365589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural network\n",
    "\n",
    "# initialize nn model\n",
    "nn_model = H2ODeepLearningEstimator(\n",
    "    epochs=50,                    # read over the data 50 times, but in mini-batches\n",
    "    hidden=[100],                 # 100 hidden units in 1 hidden layer\n",
    "    input_dropout_ratio=0.2,      # randomly drop 20% of inputs for each iteration, helps w/ generalization\n",
    "    hidden_dropout_ratios=[0.05], # randomly set 5% of hidden weights to 0 each iteration, helps w/ generalization\n",
    "    activation='TanhWithDropout', # bounded activation function that allows for dropout, tanh\n",
    "    l1=0.001,                     # L1 penalty can help generalization   \n",
    "    l2=0.01,                      # L2 penalty can increase stability in presence of highly correlated inputs\n",
    "    adaptive_rate=True,           # adjust magnitude of weight updates automatically (+stability, +accuracy)\n",
    "    stopping_rounds=5,            # stop after validation error does not decrease for 5 iterations\n",
    "    score_each_iteration=True,    # score validation error on every iteration\n",
    "    model_id='nn_model')          # for easy lookup in flow\n",
    "\n",
    "# train nn model\n",
    "nn_model.train(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    training_frame=train,\n",
    "    validation_frame=valid)\n",
    "\n",
    "# print model information\n",
    "nn_model\n",
    "\n",
    "# view detailed results at http://localhost:54321/flow/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6833671470385846\n",
      "0.6710739742243093\n",
      "0.682128781144392\n"
     ]
    }
   ],
   "source": [
    "# measure nn AUC\n",
    "print(nn_model.auc(train=True))\n",
    "print(nn_model.auc(valid=True))\n",
    "print(nn_model.model_performance(test_data=test).auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Grid Build progress: |███████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# NN with random hyperparameter search\n",
    "# train many different NN models with random hyperparameters\n",
    "# and select best model based on validation error\n",
    "\n",
    "# define random grid search parameters\n",
    "hyper_parameters = {'hidden':[[170, 320], [80, 190], [320, 160, 80], [100], [50, 50, 50, 50]],\n",
    "                    'l1':[s/1e4 for s in range(0, 1000, 100)],\n",
    "                    'l2':[s/1e5 for s in range(0, 1000, 100)],\n",
    "                    'input_dropout_ratio':[s/1e2 for s in range(0, 20, 2)]}\n",
    "\n",
    "# define search strategy\n",
    "search_criteria = {'strategy':'RandomDiscrete',\n",
    "                   'max_models':20,\n",
    "                   'max_runtime_secs':600}\n",
    "\n",
    "# initialize grid search\n",
    "gsearch = H2OGridSearch(H2ODeepLearningEstimator,\n",
    "                        hyper_params=hyper_parameters,\n",
    "                        search_criteria=search_criteria)\n",
    "\n",
    "# execute training w/ grid search\n",
    "gsearch.train(x=X,\n",
    "              y=y,\n",
    "              training_frame=train,\n",
    "              validation_frame=valid)\n",
    "\n",
    "# view detailed results at http://localhost:54321/flow/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                hidden input_dropout_ratio    l1     l2  \\\n",
      "0                [100]                0.16   0.0  0.009   \n",
      "1           [170, 320]                 0.0   0.0    0.0   \n",
      "2                [100]                0.02  0.02  0.006   \n",
      "3                [100]                 0.1  0.02  0.007   \n",
      "4                [100]                0.04   0.0  0.009   \n",
      "5                [100]                 0.1  0.03  0.005   \n",
      "6                [100]                0.02  0.04  0.008   \n",
      "7     [50, 50, 50, 50]                 0.0  0.09    0.0   \n",
      "8           [170, 320]                0.04  0.07    0.0   \n",
      "9            [80, 190]                0.18  0.06    0.0   \n",
      "10    [50, 50, 50, 50]                 0.0  0.03  0.003   \n",
      "11      [320, 160, 80]                0.02  0.03  0.004   \n",
      "12               [100]                0.06  0.08  0.005   \n",
      "13          [170, 320]                0.02  0.03    0.0   \n",
      "14    [50, 50, 50, 50]                0.18  0.09  0.005   \n",
      "15          [170, 320]                0.06  0.06  0.006   \n",
      "16           [80, 190]                0.04  0.05  0.005   \n",
      "17      [320, 160, 80]                0.08  0.04  0.005   \n",
      "18           [80, 190]                0.04  0.06  0.002   \n",
      "19           [80, 190]                0.12  0.01  0.008   \n",
      "\n",
      "                                                                model_ids  \\\n",
      "0   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_6   \n",
      "1   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "2   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "3   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "4   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "5   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_8   \n",
      "6   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "7   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_3   \n",
      "8   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "9   Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_1   \n",
      "10  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_7   \n",
      "11  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_4   \n",
      "12  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "13  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "14  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_0   \n",
      "15  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "16  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_9   \n",
      "17  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_mode...   \n",
      "18  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_2   \n",
      "19  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_5   \n",
      "\n",
      "                logloss  \n",
      "0    0.4615619185341755  \n",
      "1    0.4631509520316526  \n",
      "2    0.4634758763710253  \n",
      "3    0.4636572575131061  \n",
      "4     0.464217712738084  \n",
      "5   0.48999505867083276  \n",
      "6   0.49062275627248403  \n",
      "7    0.4907475723171484  \n",
      "8    0.4911237988824251  \n",
      "9    0.4911286095787305  \n",
      "10  0.49512470613278037  \n",
      "11   0.4994433998654282  \n",
      "12  0.49959499854177775  \n",
      "13   0.5041159184231997  \n",
      "14   0.5057321395165466  \n",
      "15   0.5069538332983858  \n",
      "16   0.5260257468986714  \n",
      "17    0.531113823831969  \n",
      "18   0.5572096846115605  \n",
      "19    0.618548704352941  \n",
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  Grid_DeepLearning_py_7_sid_927f_model_python_1488742706720_26_model_6\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.14434399936463063\n",
      "RMSE: 0.3799263078080151\n",
      "LogLoss: 0.4557177122804075\n",
      "Mean Per-Class Error: 0.3626529831265287\n",
      "AUC: 0.6853570744760814\n",
      "Gini: 0.3707141489521628\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.20044036376520524: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>5395.0</td>\n",
       "<td>2733.0</td>\n",
       "<td>0.3362</td>\n",
       "<td> (2733.0/8128.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>754.0</td>\n",
       "<td>1184.0</td>\n",
       "<td>0.3891</td>\n",
       "<td> (754.0/1938.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>6149.0</td>\n",
       "<td>3917.0</td>\n",
       "<td>0.3464</td>\n",
       "<td> (3487.0/10066.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ----------------\n",
       "0      5395  2733  0.3362   (2733.0/8128.0)\n",
       "1      754   1184  0.3891   (754.0/1938.0)\n",
       "Total  6149  3917  0.3464   (3487.0/10066.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2004404</td>\n",
       "<td>0.4044406</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1174692</td>\n",
       "<td>0.5669583</td>\n",
       "<td>307.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3157197</td>\n",
       "<td>0.3770094</td>\n",
       "<td>108.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4498824</td>\n",
       "<td>0.8094576</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.5407400</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0216523</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.5407400</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2798110</td>\n",
       "<td>0.2277725</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1912503</td>\n",
       "<td>0.6341043</td>\n",
       "<td>223.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2004404</td>\n",
       "<td>0.6373470</td>\n",
       "<td>213.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.20044      0.404441  213\n",
       "max f2                       0.117469     0.566958  307\n",
       "max f0point5                 0.31572      0.377009  108\n",
       "max accuracy                 0.449882     0.809458  21\n",
       "max precision                0.54074      1         0\n",
       "max recall                   0.0216523    1         397\n",
       "max specificity              0.54074      1         0\n",
       "max absolute_mcc             0.279811     0.227773  138\n",
       "max min_per_class_accuracy   0.19125      0.634104  223\n",
       "max mean_per_class_accuracy  0.20044      0.637347  213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.25 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100338</td>\n",
       "<td>0.4507984</td>\n",
       "<td>2.9827014</td>\n",
       "<td>2.9827014</td>\n",
       "<td>0.5742574</td>\n",
       "<td>0.5742574</td>\n",
       "<td>0.0299278</td>\n",
       "<td>0.0299278</td>\n",
       "<td>198.2701366</td>\n",
       "<td>198.2701366</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200676</td>\n",
       "<td>0.4308680</td>\n",
       "<td>2.3655907</td>\n",
       "<td>2.6741461</td>\n",
       "<td>0.4554455</td>\n",
       "<td>0.5148515</td>\n",
       "<td>0.0237358</td>\n",
       "<td>0.0536636</td>\n",
       "<td>136.5590739</td>\n",
       "<td>167.4146052</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300020</td>\n",
       "<td>0.4157331</td>\n",
       "<td>2.5450671</td>\n",
       "<td>2.6314047</td>\n",
       "<td>0.49</td>\n",
       "<td>0.5066225</td>\n",
       "<td>0.0252838</td>\n",
       "<td>0.0789474</td>\n",
       "<td>154.5067079</td>\n",
       "<td>163.1404671</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400358</td>\n",
       "<td>0.4044312</td>\n",
       "<td>2.3141649</td>\n",
       "<td>2.5518979</td>\n",
       "<td>0.4455446</td>\n",
       "<td>0.4913151</td>\n",
       "<td>0.0232198</td>\n",
       "<td>0.1021672</td>\n",
       "<td>131.4164853</td>\n",
       "<td>155.1897917</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500695</td>\n",
       "<td>0.3940745</td>\n",
       "<td>1.6456283</td>\n",
       "<td>2.3702844</td>\n",
       "<td>0.3168317</td>\n",
       "<td>0.4563492</td>\n",
       "<td>0.0165119</td>\n",
       "<td>0.1186791</td>\n",
       "<td>64.5628340</td>\n",
       "<td>137.0284371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000397</td>\n",
       "<td>0.3492473</td>\n",
       "<td>1.9929320</td>\n",
       "<td>2.1817955</td>\n",
       "<td>0.3836978</td>\n",
       "<td>0.4200596</td>\n",
       "<td>0.0995872</td>\n",
       "<td>0.2182663</td>\n",
       "<td>99.2931985</td>\n",
       "<td>118.1795543</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500099</td>\n",
       "<td>0.3124026</td>\n",
       "<td>1.8380409</td>\n",
       "<td>2.0672865</td>\n",
       "<td>0.3538767</td>\n",
       "<td>0.3980132</td>\n",
       "<td>0.0918473</td>\n",
       "<td>0.3101135</td>\n",
       "<td>83.8040898</td>\n",
       "<td>106.7286545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000795</td>\n",
       "<td>0.2830674</td>\n",
       "<td>1.4840041</td>\n",
       "<td>1.9213211</td>\n",
       "<td>0.2857143</td>\n",
       "<td>0.3699106</td>\n",
       "<td>0.0743034</td>\n",
       "<td>0.3844169</td>\n",
       "<td>48.4004128</td>\n",
       "<td>92.1321134</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000199</td>\n",
       "<td>0.2353247</td>\n",
       "<td>1.2391287</td>\n",
       "<td>1.6940742</td>\n",
       "<td>0.2385686</td>\n",
       "<td>0.3261589</td>\n",
       "<td>0.1238390</td>\n",
       "<td>0.5082559</td>\n",
       "<td>23.9128695</td>\n",
       "<td>69.4074249</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000596</td>\n",
       "<td>0.1961366</td>\n",
       "<td>1.0986346</td>\n",
       "<td>1.5451774</td>\n",
       "<td>0.2115194</td>\n",
       "<td>0.2974919</td>\n",
       "<td>0.1099071</td>\n",
       "<td>0.6181631</td>\n",
       "<td>9.8634635</td>\n",
       "<td>54.5177380</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1666116</td>\n",
       "<td>0.9035313</td>\n",
       "<td>1.4169247</td>\n",
       "<td>0.1739563</td>\n",
       "<td>0.2727995</td>\n",
       "<td>0.0902993</td>\n",
       "<td>0.7084623</td>\n",
       "<td>-9.6468660</td>\n",
       "<td>41.6924665</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000397</td>\n",
       "<td>0.1423090</td>\n",
       "<td>0.8665287</td>\n",
       "<td>1.3251616</td>\n",
       "<td>0.1668322</td>\n",
       "<td>0.2551325</td>\n",
       "<td>0.0866873</td>\n",
       "<td>0.7951496</td>\n",
       "<td>-13.3471274</td>\n",
       "<td>32.5161633</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999801</td>\n",
       "<td>0.1184163</td>\n",
       "<td>0.6815208</td>\n",
       "<td>1.2332651</td>\n",
       "<td>0.1312127</td>\n",
       "<td>0.2374397</td>\n",
       "<td>0.0681115</td>\n",
       "<td>0.8632611</td>\n",
       "<td>-31.8479218</td>\n",
       "<td>23.3265139</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000199</td>\n",
       "<td>0.0957019</td>\n",
       "<td>0.5673700</td>\n",
       "<td>1.1499972</td>\n",
       "<td>0.1092354</td>\n",
       "<td>0.2214082</td>\n",
       "<td>0.0567595</td>\n",
       "<td>0.9200206</td>\n",
       "<td>-43.2630001</td>\n",
       "<td>14.9997238</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999603</td>\n",
       "<td>0.0708855</td>\n",
       "<td>0.4595102</td>\n",
       "<td>1.0733188</td>\n",
       "<td>0.0884692</td>\n",
       "<td>0.2066453</td>\n",
       "<td>0.0459236</td>\n",
       "<td>0.9659443</td>\n",
       "<td>-54.0489775</td>\n",
       "<td>7.3318804</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0148806</td>\n",
       "<td>0.3404220</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0655412</td>\n",
       "<td>0.1925293</td>\n",
       "<td>0.0340557</td>\n",
       "<td>1.0</td>\n",
       "<td>-65.9578000</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100338                   0.450798           2.9827    2.9827             0.574257         0.574257                    0.0299278       0.0299278                  198.27    198.27\n",
       "    2        0.0200676                   0.430868           2.36559   2.67415            0.455446         0.514851                    0.0237358       0.0536636                  136.559   167.415\n",
       "    3        0.030002                    0.415733           2.54507   2.6314             0.49             0.506623                    0.0252838       0.0789474                  154.507   163.14\n",
       "    4        0.0400358                   0.404431           2.31416   2.5519             0.445545         0.491315                    0.0232198       0.102167                   131.416   155.19\n",
       "    5        0.0500695                   0.394075           1.64563   2.37028            0.316832         0.456349                    0.0165119       0.118679                   64.5628   137.028\n",
       "    6        0.10004                     0.349247           1.99293   2.1818             0.383698         0.42006                     0.0995872       0.218266                   99.2932   118.18\n",
       "    7        0.15001                     0.312403           1.83804   2.06729            0.353877         0.398013                    0.0918473       0.310114                   83.8041   106.729\n",
       "    8        0.200079                    0.283067           1.484     1.92132            0.285714         0.369911                    0.0743034       0.384417                   48.4004   92.1321\n",
       "    9        0.30002                     0.235325           1.23913   1.69407            0.238569         0.326159                    0.123839        0.508256                   23.9129   69.4074\n",
       "    10       0.40006                     0.196137           1.09863   1.54518            0.211519         0.297492                    0.109907        0.618163                   9.86346   54.5177\n",
       "    11       0.5                         0.166612           0.903531  1.41692            0.173956         0.2728                      0.0902993       0.708462                   -9.64687  41.6925\n",
       "    12       0.60004                     0.142309           0.866529  1.32516            0.166832         0.255132                    0.0866873       0.79515                    -13.3471  32.5162\n",
       "    13       0.69998                     0.118416           0.681521  1.23327            0.131213         0.23744                     0.0681115       0.863261                   -31.8479  23.3265\n",
       "    14       0.80002                     0.0957019          0.56737   1.15               0.109235         0.221408                    0.0567595       0.920021                   -43.263   14.9997\n",
       "    15       0.89996                     0.0708855          0.45951   1.07332            0.0884692        0.206645                    0.0459236       0.965944                   -54.049   7.33188\n",
       "    16       1                           0.0148806          0.340422  1                  0.0655412        0.192529                    0.0340557       1                          -65.9578  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.1463921146493909\n",
      "RMSE: 0.3826122249084455\n",
      "LogLoss: 0.4615619185341755\n",
      "Mean Per-Class Error: 0.3732780920214249\n",
      "AUC: 0.6713393533381893\n",
      "Gini: 0.34267870667637856\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.190501771334423: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>25369.0</td>\n",
       "<td>14472.0</td>\n",
       "<td>0.3632</td>\n",
       "<td> (14472.0/39841.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>3643.0</td>\n",
       "<td>5861.0</td>\n",
       "<td>0.3833</td>\n",
       "<td> (3643.0/9504.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>29012.0</td>\n",
       "<td>20333.0</td>\n",
       "<td>0.3671</td>\n",
       "<td> (18115.0/49345.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      25369  14472  0.3632   (14472.0/39841.0)\n",
       "1      3643   5861   0.3833   (3643.0/9504.0)\n",
       "Total  29012  20333  0.3671   (18115.0/49345.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1905018</td>\n",
       "<td>0.3928679</td>\n",
       "<td>224.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0984593</td>\n",
       "<td>0.5619344</td>\n",
       "<td>325.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2729567</td>\n",
       "<td>0.3501322</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5413172</td>\n",
       "<td>0.8073766</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.4490005</td>\n",
       "<td>0.4901186</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0221527</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.5413172</td>\n",
       "<td>0.9999749</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2221138</td>\n",
       "<td>0.2046904</td>\n",
       "<td>191.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1872289</td>\n",
       "<td>0.6258126</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1905018</td>\n",
       "<td>0.6267219</td>\n",
       "<td>224.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.190502     0.392868  224\n",
       "max f2                       0.0984593    0.561934  325\n",
       "max f0point5                 0.272957     0.350132  146\n",
       "max accuracy                 0.541317     0.807377  0\n",
       "max precision                0.449001     0.490119  21\n",
       "max recall                   0.0221527    1         397\n",
       "max specificity              0.541317     0.999975  0\n",
       "max absolute_mcc             0.222114     0.20469   191\n",
       "max min_per_class_accuracy   0.187229     0.625813  227\n",
       "max mean_per_class_accuracy  0.190502     0.626722  224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100111</td>\n",
       "<td>0.4483748</td>\n",
       "<td>2.5539715</td>\n",
       "<td>2.5539715</td>\n",
       "<td>0.4919028</td>\n",
       "<td>0.4919028</td>\n",
       "<td>0.0255682</td>\n",
       "<td>0.0255682</td>\n",
       "<td>155.3971522</td>\n",
       "<td>155.3971522</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200020</td>\n",
       "<td>0.4289208</td>\n",
       "<td>2.2326758</td>\n",
       "<td>2.3934864</td>\n",
       "<td>0.4300203</td>\n",
       "<td>0.4609929</td>\n",
       "<td>0.0223064</td>\n",
       "<td>0.0478746</td>\n",
       "<td>123.2675812</td>\n",
       "<td>139.3486430</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300132</td>\n",
       "<td>0.4142494</td>\n",
       "<td>2.2176461</td>\n",
       "<td>2.3348334</td>\n",
       "<td>0.4271255</td>\n",
       "<td>0.4496962</td>\n",
       "<td>0.0222012</td>\n",
       "<td>0.0700758</td>\n",
       "<td>121.7646054</td>\n",
       "<td>133.4833395</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400041</td>\n",
       "<td>0.4009306</td>\n",
       "<td>2.0957664</td>\n",
       "<td>2.2751272</td>\n",
       "<td>0.4036511</td>\n",
       "<td>0.4381966</td>\n",
       "<td>0.0209386</td>\n",
       "<td>0.0910143</td>\n",
       "<td>109.5766446</td>\n",
       "<td>127.5127211</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500152</td>\n",
       "<td>0.3901181</td>\n",
       "<td>1.8287697</td>\n",
       "<td>2.1857834</td>\n",
       "<td>0.3522267</td>\n",
       "<td>0.4209887</td>\n",
       "<td>0.0183081</td>\n",
       "<td>0.1093224</td>\n",
       "<td>82.8769732</td>\n",
       "<td>118.5783372</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000101</td>\n",
       "<td>0.3452921</td>\n",
       "<td>1.8583533</td>\n",
       "<td>2.0221015</td>\n",
       "<td>0.3579246</td>\n",
       "<td>0.3894630</td>\n",
       "<td>0.0929082</td>\n",
       "<td>0.2022306</td>\n",
       "<td>85.8353285</td>\n",
       "<td>102.2101503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500051</td>\n",
       "<td>0.3098830</td>\n",
       "<td>1.7005090</td>\n",
       "<td>1.9149185</td>\n",
       "<td>0.3275233</td>\n",
       "<td>0.3688192</td>\n",
       "<td>0.0850168</td>\n",
       "<td>0.2872475</td>\n",
       "<td>70.0509008</td>\n",
       "<td>91.4918487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2796234</td>\n",
       "<td>1.4079709</td>\n",
       "<td>1.7881944</td>\n",
       "<td>0.2711796</td>\n",
       "<td>0.3444118</td>\n",
       "<td>0.0703914</td>\n",
       "<td>0.3576389</td>\n",
       "<td>40.7970949</td>\n",
       "<td>78.8194444</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000101</td>\n",
       "<td>0.2306099</td>\n",
       "<td>1.3340399</td>\n",
       "<td>1.6367994</td>\n",
       "<td>0.2569402</td>\n",
       "<td>0.3152526</td>\n",
       "<td>0.1334175</td>\n",
       "<td>0.4910564</td>\n",
       "<td>33.4039909</td>\n",
       "<td>63.6799373</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.1934167</td>\n",
       "<td>1.1175375</td>\n",
       "<td>1.5069971</td>\n",
       "<td>0.2152412</td>\n",
       "<td>0.2902523</td>\n",
       "<td>0.1117424</td>\n",
       "<td>0.6027988</td>\n",
       "<td>11.7537480</td>\n",
       "<td>50.6997054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000101</td>\n",
       "<td>0.1649665</td>\n",
       "<td>0.9679154</td>\n",
       "<td>1.3991720</td>\n",
       "<td>0.1864235</td>\n",
       "<td>0.2694849</td>\n",
       "<td>0.0968013</td>\n",
       "<td>0.6996002</td>\n",
       "<td>-3.2084608</td>\n",
       "<td>39.9171982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1403811</td>\n",
       "<td>0.7818553</td>\n",
       "<td>1.2962963</td>\n",
       "<td>0.1505878</td>\n",
       "<td>0.2496707</td>\n",
       "<td>0.0781776</td>\n",
       "<td>0.7777778</td>\n",
       "<td>-21.8144682</td>\n",
       "<td>29.6296296</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999899</td>\n",
       "<td>0.1180750</td>\n",
       "<td>0.7155607</td>\n",
       "<td>1.2133413</td>\n",
       "<td>0.1378192</td>\n",
       "<td>0.2336933</td>\n",
       "<td>0.0715488</td>\n",
       "<td>0.8493266</td>\n",
       "<td>-28.4439279</td>\n",
       "<td>21.3341277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0953103</td>\n",
       "<td>0.6607075</td>\n",
       "<td>1.1442551</td>\n",
       "<td>0.1272543</td>\n",
       "<td>0.2203871</td>\n",
       "<td>0.0660774</td>\n",
       "<td>0.9154040</td>\n",
       "<td>-33.9292537</td>\n",
       "<td>14.4255051</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999899</td>\n",
       "<td>0.0712494</td>\n",
       "<td>0.4924741</td>\n",
       "<td>1.0718415</td>\n",
       "<td>0.0948520</td>\n",
       "<td>0.2064400</td>\n",
       "<td>0.0492424</td>\n",
       "<td>0.9646465</td>\n",
       "<td>-50.7525856</td>\n",
       "<td>7.1841473</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0135228</td>\n",
       "<td>0.3534995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0680851</td>\n",
       "<td>0.1926031</td>\n",
       "<td>0.0353535</td>\n",
       "<td>1.0</td>\n",
       "<td>-64.6500466</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100111                   0.448375           2.55397   2.55397            0.491903         0.491903                    0.0255682       0.0255682                  155.397   155.397\n",
       "    2        0.020002                    0.428921           2.23268   2.39349            0.43002          0.460993                    0.0223064       0.0478746                  123.268   139.349\n",
       "    3        0.0300132                   0.414249           2.21765   2.33483            0.427126         0.449696                    0.0222012       0.0700758                  121.765   133.483\n",
       "    4        0.0400041                   0.400931           2.09577   2.27513            0.403651         0.438197                    0.0209386       0.0910143                  109.577   127.513\n",
       "    5        0.0500152                   0.390118           1.82877   2.18578            0.352227         0.420989                    0.0183081       0.109322                   82.877    118.578\n",
       "    6        0.10001                     0.345292           1.85835   2.0221             0.357925         0.389463                    0.0929082       0.202231                   85.8353   102.21\n",
       "    7        0.150005                    0.309883           1.70051   1.91492            0.327523         0.368819                    0.0850168       0.287247                   70.0509   91.4918\n",
       "    8        0.2                         0.279623           1.40797   1.78819            0.27118          0.344412                    0.0703914       0.357639                   40.7971   78.8194\n",
       "    9        0.30001                     0.23061            1.33404   1.6368             0.25694          0.315253                    0.133418        0.491056                   33.404    63.6799\n",
       "    10       0.4                         0.193417           1.11754   1.507              0.215241         0.290252                    0.111742        0.602799                   11.7537   50.6997\n",
       "    11       0.50001                     0.164967           0.967915  1.39917            0.186424         0.269485                    0.0968013       0.6996                     -3.20846  39.9172\n",
       "    12       0.6                         0.140381           0.781855  1.2963             0.150588         0.249671                    0.0781776       0.777778                   -21.8145  29.6296\n",
       "    13       0.69999                     0.118075           0.715561  1.21334            0.137819         0.233693                    0.0715488       0.849327                   -28.4439  21.3341\n",
       "    14       0.8                         0.0953103          0.660707  1.14426            0.127254         0.220387                    0.0660774       0.915404                   -33.9293  14.4255\n",
       "    15       0.89999                     0.0712494          0.492474  1.07184            0.094852         0.20644                     0.0492424       0.964646                   -50.7526  7.18415\n",
       "    16       1                           0.0135228          0.3535    1                  0.0680851        0.192603                    0.0353535       1                          -64.65    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:39:27</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:39:27</td>\n",
       "<td>35.360 sec</td>\n",
       "<td>129549 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>65552.0</td>\n",
       "<td>0.3809488</td>\n",
       "<td>0.4580211</td>\n",
       "<td>0.6837314</td>\n",
       "<td>3.0341273</td>\n",
       "<td>0.3337969</td>\n",
       "<td>0.3833183</td>\n",
       "<td>0.4642936</td>\n",
       "<td>0.6704782</td>\n",
       "<td>2.4278495</td>\n",
       "<td>0.3507144</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-03-05 14:39:29</td>\n",
       "<td>37.554 sec</td>\n",
       "<td>256965 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>655520.0</td>\n",
       "<td>0.3799263</td>\n",
       "<td>0.4557177</td>\n",
       "<td>0.6853571</td>\n",
       "<td>2.9827014</td>\n",
       "<td>0.3464137</td>\n",
       "<td>0.3826122</td>\n",
       "<td>0.4615619</td>\n",
       "<td>0.6713394</td>\n",
       "<td>2.5539715</td>\n",
       "<td>0.3671091</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "    2017-03-05 14:39:27  0.000 sec                     0         0             0          nan              nan                 nan             nan              nan                              nan                nan                   nan               nan                nan\n",
       "    2017-03-05 14:39:27  35.360 sec  129549 obs/sec    1         1             65552      0.380949         0.458021            0.683731        3.03413          0.333797                         0.383318           0.464294              0.670478          2.42785            0.350714\n",
       "    2017-03-05 14:39:29  37.554 sec  256965 obs/sec    10        10            655520     0.379926         0.455718            0.685357        2.9827           0.346414                         0.382612           0.461562              0.671339          2.55397            0.367109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show grid search results\n",
    "gsearch.show()\n",
    "\n",
    "# select best model\n",
    "nn_model2 = gsearch.get_grid()[0]\n",
    "\n",
    "# print model information\n",
    "nn_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6853570744760814\n",
      "0.6713393533381893\n",
      "0.6818205971758765\n"
     ]
    }
   ],
   "source": [
    "# measure nn AUC\n",
    "print(nn_model2.auc(train=True))\n",
    "print(nn_model2.auc(valid=True))\n",
    "print(nn_model2.model_performance(test_data=test).auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |█████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAPwCAYAAAA2yWiMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSimZDLEmSpKLZEEuSJKlo/wkaGNe9uFAp0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11948dbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# partial dependence plots are a powerful machine learning interpretation tool\n",
    "# to calculate partial dependence across the domain a variable\n",
    "# hold column of interest at constant value\n",
    "# find the mean prediction of the model with this column constant\n",
    "# repeat for multiple values of the variable of interest\n",
    "# h2o has a built-in function for partial dependence as well\n",
    "par_dep_dti1 = nn_model2.partial_plot(data=train, cols=['STD_IMP_REP_dti'], server=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_927f closed.\n"
     ]
    }
   ],
   "source": [
    "# shutdown h2o\n",
    "h2o.cluster().shutdown(prompt=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
